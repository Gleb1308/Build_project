{"cells":[{"cell_type":"markdown","metadata":{"id":"KtY6Rvf2Lb2O"},"source":["# Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TSwEkl7sjuSz"},"outputs":[],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCC42GMw80AV"},"outputs":[],"source":["from ultralytics import YOLO\n","from ultralytics import RTDETR\n","from google.colab import files\n","from shutil import copy\n","from shutil import make_archive\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","sns.set_theme()\n","import os\n","import zipfile\n","import gdown\n","import yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KY_sWLtYSp3U"},"outputs":[],"source":["!mkdir ~/.kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ufzuH__7Sxy7"},"outputs":[],"source":["!echo '{\"username\":\"kaggle_username\",\"key\":\"kaggle_key\"}' > ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hn1GzFc1T5yS"},"outputs":[],"source":["!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2748,"status":"ok","timestamp":1722629231089,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"},"user_tz":-180},"id":"vDn-Rw8OY-fN","outputId":"41078891-2679-436e-c994-e6b1383f83fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n","Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"]}],"source":["!pip install kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":361178,"status":"ok","timestamp":1722629592259,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"},"user_tz":-180},"id":"6fmOJJZEZDaD","outputId":"b7ece4e3-ba60-42db-c8e3-288e67e2b98a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/glebsukhomlyn/kitti-dataset\n","License(s): Apache 2.0\n","Downloading kitti-dataset.zip to .\n","100% 5.69G/5.69G [06:00<00:00, 18.6MB/s]\n","100% 5.69G/5.69G [06:00<00:00, 16.9MB/s]\n"]}],"source":["!kaggle datasets download -d glebsukhomlyn/kitti-dataset -p ./"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"It-1_MpEbN8M"},"outputs":[],"source":["zip_ref = zipfile.ZipFile(\"./kitti-dataset.zip\", 'r')\n","zip_ref.extractall(\"./kitti\")\n","zip_ref.close()"]},{"cell_type":"markdown","metadata":{"id":"qTwuxu1WRt8j"},"source":["# Eval finetuned models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YRBz8sJWR3gK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722629767217,"user_tz":-180,"elapsed":27816,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"}},"outputId":"210df69c-5335-416a-afa8-6610878e58d0"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1U7bRLXEgh4Am4qIQ0uQgfi4koRGvK8NN\n","From (redirected): https://drive.google.com/uc?id=1U7bRLXEgh4Am4qIQ0uQgfi4koRGvK8NN&confirm=t&uuid=9fd79567-5892-484b-81d3-dc6d038137c5\n","To: /content/weights.zip\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.10G/1.10G [00:14<00:00, 78.6MB/s]\n"]}],"source":["file_id = '1U7bRLXEgh4Am4qIQ0uQgfi4koRGvK8NN'\n","gdown.download(f\"https://drive.google.com/uc?id={file_id}\", 'weights.zip')\n","zip_ref = zipfile.ZipFile('/content/weights.zip', 'r')\n","zip_ref.extractall(\"/content/weights\")"]},{"cell_type":"code","source":["with open('kitti/kitti.yaml') as f:\n","  templates = yaml.safe_load(f)\n","templates['val'] = templates['test']\n","\n","with open('kitti/kitti_val.yaml', 'w') as f:\n","    yaml.dump(templates, f)"],"metadata":{"id":"2EFSQ242JwKA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d = {'model':[], 'map50-95':[], 'map50':[], 'map75':[]}\n","\n","for model_path in os.listdir('/content/weights'):\n","  if model_path == '__MACOSX':\n","    continue\n","  print('/////////////////////////')\n","  print(f'model = {model_path}')\n","  model = YOLO('/content/weights/'+model_path)\n","  d['model'].append(model_path)\n","  metrics = model.val(data='./kitti/kitti_val.yaml')\n","  d['map50-95'].append(metrics.box.map)\n","  d['map50'].append(metrics.box.map50)\n","  d['map75'].append(metrics.box.map75)"],"metadata":{"id":"i52uD1_wFu7S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722583706354,"user_tz":-180,"elapsed":750793,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"}},"outputId":"0096976c-aae6-46c0-a62e-70eca97fa275"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/////////////////////////\n","model = best_yolov8x-worldv2.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","YOLOv8x-worldv2 summary (fused): 295 layers, 72,856,217 parameters, 0 gradients, 275.6 GFLOPs\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 24.1MB/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:05<00:00, 202.53it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kitti/labels/test.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:18<00:00,  3.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.925      0.892      0.943       0.72\n","                   Car       1005       4274      0.936      0.936      0.974      0.818\n","               Cyclist        174        256      0.914      0.844      0.914      0.629\n","                  Misc        120        146      0.985      0.911      0.954      0.726\n","            Pedestrian        250        686      0.923      0.733      0.844      0.524\n","        Person_sitting         13         27      0.846      0.889      0.936      0.691\n","                  Tram         43         62      0.951      0.932       0.98      0.734\n","                 Truck        153        161      0.934      0.944      0.972       0.84\n","                   Van        339        464       0.91      0.944      0.973      0.796\n","Speed: 0.1ms preprocess, 8.7ms inference, 0.0ms loss, 3.2ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n","/////////////////////////\n","model = best_yolov8m.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 218 layers, 25,844,392 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:11<00:00,  6.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.898       0.86      0.917      0.684\n","                   Car       1005       4274      0.926       0.92      0.964      0.792\n","               Cyclist        174        256      0.886      0.832      0.898      0.612\n","                  Misc        120        146      0.911      0.842      0.921      0.689\n","            Pedestrian        250        686      0.914      0.696      0.826      0.502\n","        Person_sitting         13         27      0.799      0.815      0.852      0.556\n","                  Tram         43         62      0.892      0.931      0.949      0.707\n","                 Truck        153        161      0.943       0.95      0.973      0.849\n","                   Van        339        464      0.912      0.896      0.956      0.766\n","Speed: 0.1ms preprocess, 3.6ms inference, 0.0ms loss, 3.2ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val2\u001b[0m\n","/////////////////////////\n","model = best_yolov8s.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 168 layers, 11,128,680 parameters, 0 gradients, 28.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:10<00:00,  6.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.882      0.786      0.866      0.602\n","                   Car       1005       4274      0.888      0.905      0.947      0.739\n","               Cyclist        174        256      0.899      0.719      0.822      0.516\n","                  Misc        120        146      0.848      0.712      0.828       0.58\n","            Pedestrian        250        686       0.84      0.641      0.757      0.431\n","        Person_sitting         13         27      0.794      0.741      0.759      0.406\n","                  Tram         43         62      0.963      0.835      0.947      0.659\n","                 Truck        153        161      0.932      0.907      0.949      0.787\n","                   Van        339        464      0.895      0.831      0.915      0.699\n","Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val3\u001b[0m\n","/////////////////////////\n","model = best_yolov8m-worldv2.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","YOLOv8m-worldv2 summary (fused): 245 layers, 28,358,830 parameters, 0 gradients, 87.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:11<00:00,  6.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.906      0.855       0.92      0.686\n","                   Car       1005       4274      0.929      0.916      0.962       0.79\n","               Cyclist        174        256      0.927      0.793      0.896      0.602\n","                  Misc        120        146      0.919      0.859      0.924      0.668\n","            Pedestrian        250        686      0.915      0.701      0.838      0.496\n","        Person_sitting         13         27      0.782      0.815       0.83      0.601\n","                  Tram         43         62      0.927      0.952      0.983      0.733\n","                 Truck        153        161      0.943      0.925      0.976      0.834\n","                   Van        339        464      0.906      0.877      0.952      0.767\n","Speed: 0.2ms preprocess, 3.7ms inference, 0.0ms loss, 3.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val4\u001b[0m\n","/////////////////////////\n","model = last_yolov8m-worldv2.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","YOLOv8m-worldv2 summary (fused): 245 layers, 28,358,830 parameters, 0 gradients, 87.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [01:32<00:00,  1.30s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.907      0.826      0.901      0.658\n","                   Car       1005       4274      0.918      0.903      0.957       0.77\n","               Cyclist        174        256      0.909      0.738      0.844      0.551\n","                  Misc        120        146      0.961      0.836      0.908      0.645\n","            Pedestrian        250        686       0.92      0.656      0.809      0.478\n","        Person_sitting         13         27      0.742      0.778       0.81      0.559\n","                  Tram         43         62      0.944      0.903      0.974      0.713\n","                 Truck        153        161      0.942      0.913      0.963      0.808\n","                   Van        339        464       0.92      0.879      0.943      0.742\n","Speed: 0.1ms preprocess, 3.0ms inference, 0.0ms loss, 3.8ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val5\u001b[0m\n","/////////////////////////\n","model = last_yolov8x-worldv2.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","YOLOv8x-worldv2 summary (fused): 295 layers, 72,856,217 parameters, 0 gradients, 275.6 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:16<00:00,  4.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.916      0.859      0.927      0.696\n","                   Car       1005       4274      0.945       0.91      0.968      0.801\n","               Cyclist        174        256      0.901      0.782      0.881      0.585\n","                  Misc        120        146      0.929      0.884      0.939      0.715\n","            Pedestrian        250        686      0.922      0.676      0.818      0.501\n","        Person_sitting         13         27      0.816      0.815      0.883       0.61\n","                  Tram         43         62      0.935      0.952       0.98      0.738\n","                 Truck        153        161      0.956      0.939      0.978      0.838\n","                   Van        339        464      0.927      0.918      0.968      0.785\n","Speed: 0.1ms preprocess, 8.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val6\u001b[0m\n","/////////////////////////\n","model = last_yolov8x.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 268 layers, 68,131,272 parameters, 0 gradients, 257.4 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:16<00:00,  4.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.916      0.876      0.926      0.724\n","                   Car       1005       4274      0.937      0.932      0.971      0.819\n","               Cyclist        174        256      0.922       0.83      0.904      0.648\n","                  Misc        120        146      0.955      0.871      0.935      0.755\n","            Pedestrian        250        686       0.94      0.708      0.841      0.528\n","        Person_sitting         13         27      0.816      0.815      0.851       0.62\n","                  Tram         43         62       0.88       0.95      0.969      0.757\n","                 Truck        153        161      0.947      0.963      0.968      0.863\n","                   Van        339        464      0.929       0.94      0.964      0.801\n","Speed: 0.2ms preprocess, 7.9ms inference, 0.0ms loss, 2.9ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val7\u001b[0m\n","/////////////////////////\n","model = best_yolov8l-worldv2.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","YOLOv8l-worldv2 summary (fused): 295 layers, 46,807,922 parameters, 0 gradients, 177.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:14<00:00,  4.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.914      0.853      0.924      0.696\n","                   Car       1005       4274      0.946      0.912      0.968      0.802\n","               Cyclist        174        256      0.936      0.816      0.896      0.611\n","                  Misc        120        146      0.948      0.869      0.938      0.711\n","            Pedestrian        250        686      0.944      0.665      0.841      0.512\n","        Person_sitting         13         27      0.742      0.815       0.84       0.58\n","                  Tram         43         62      0.944      0.919      0.971      0.715\n","                 Truck        153        161      0.949      0.957      0.986      0.856\n","                   Van        339        464      0.904      0.873      0.954      0.781\n","Speed: 0.2ms preprocess, 6.0ms inference, 0.0ms loss, 3.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val8\u001b[0m\n","/////////////////////////\n","model = last_yolov8l-worldv2.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","YOLOv8l-worldv2 summary (fused): 295 layers, 46,807,922 parameters, 0 gradients, 177.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:14<00:00,  5.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.861      0.867      0.906      0.673\n","                   Car       1005       4274      0.919      0.928      0.964      0.792\n","               Cyclist        174        256      0.854      0.824       0.88      0.568\n","                  Misc        120        146      0.908      0.884      0.935      0.675\n","            Pedestrian        250        686      0.869      0.717      0.814      0.492\n","        Person_sitting         13         27      0.687      0.814      0.784       0.55\n","                  Tram         43         62      0.849      0.907      0.951       0.71\n","                 Truck        153        161      0.928       0.95      0.977      0.846\n","                   Van        339        464      0.876      0.909      0.944       0.75\n","Speed: 0.1ms preprocess, 5.7ms inference, 0.0ms loss, 3.2ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val9\u001b[0m\n","/////////////////////////\n","model = last_yolov8m.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 218 layers, 25,844,392 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:11<00:00,  6.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.893      0.866      0.922       0.68\n","                   Car       1005       4274      0.906      0.928      0.961      0.786\n","               Cyclist        174        256      0.896       0.82      0.895      0.589\n","                  Misc        120        146      0.902      0.836      0.918       0.69\n","            Pedestrian        250        686       0.88      0.719      0.815      0.493\n","        Person_sitting         13         27       0.82      0.842       0.89      0.549\n","                  Tram         43         62      0.886      0.903      0.963      0.728\n","                 Truck        153        161      0.951      0.956      0.972      0.841\n","                   Van        339        464      0.901       0.92      0.963      0.767\n","Speed: 0.3ms preprocess, 4.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val10\u001b[0m\n","/////////////////////////\n","model = best_yolov8x.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 268 layers, 68,131,272 parameters, 0 gradients, 257.4 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:16<00:00,  4.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.926       0.88      0.933      0.731\n","                   Car       1005       4274      0.944      0.929      0.974      0.825\n","               Cyclist        174        256      0.946      0.848      0.921      0.654\n","                  Misc        120        146      0.932      0.904      0.945       0.75\n","            Pedestrian        250        686      0.934      0.707      0.841      0.524\n","        Person_sitting         13         27      0.868      0.815      0.881      0.663\n","                  Tram         43         62      0.902      0.935      0.964      0.756\n","                 Truck        153        161       0.95      0.963      0.969      0.869\n","                   Van        339        464      0.931      0.936      0.969      0.807\n","Speed: 0.2ms preprocess, 9.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val11\u001b[0m\n","/////////////////////////\n","model = last_yolov8s.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 168 layers, 11,128,680 parameters, 0 gradients, 28.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:10<00:00,  6.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.873      0.776      0.866      0.591\n","                   Car       1005       4274      0.897      0.886      0.943      0.726\n","               Cyclist        174        256      0.867       0.68      0.791      0.486\n","                  Misc        120        146      0.867      0.705      0.828      0.576\n","            Pedestrian        250        686      0.876      0.598      0.742      0.416\n","        Person_sitting         13         27      0.824      0.741       0.82      0.421\n","                  Tram         43         62      0.881      0.839      0.941       0.65\n","                 Truck        153        161      0.918      0.907      0.949      0.776\n","                   Van        339        464      0.851       0.85      0.913      0.679\n","Speed: 0.1ms preprocess, 1.9ms inference, 0.0ms loss, 3.2ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val12\u001b[0m\n","/////////////////////////\n","model = best_yolov8l.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 268 layers, 43,612,776 parameters, 0 gradients, 164.8 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:13<00:00,  5.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.916      0.871      0.928      0.714\n","                   Car       1005       4274      0.951       0.92       0.97      0.815\n","               Cyclist        174        256      0.925      0.816      0.908      0.644\n","                  Misc        120        146      0.948      0.856      0.939       0.73\n","            Pedestrian        250        686      0.942       0.69      0.838      0.518\n","        Person_sitting         13         27      0.797      0.871      0.871        0.6\n","                  Tram         43         62      0.884      0.919      0.963      0.762\n","                 Truck        153        161      0.964      0.963      0.969      0.847\n","                   Van        339        464      0.919      0.933      0.966      0.799\n","Speed: 0.2ms preprocess, 6.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val13\u001b[0m\n","/////////////////////////\n","model = last_yolov8l.pt\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 268 layers, 43,612,776 parameters, 0 gradients, 164.8 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:13<00:00,  5.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.908      0.877       0.93       0.72\n","                   Car       1005       4274      0.938      0.933       0.97      0.814\n","               Cyclist        174        256      0.933       0.82      0.905      0.637\n","                  Misc        120        146      0.933       0.87      0.951      0.735\n","            Pedestrian        250        686      0.936      0.714      0.846      0.522\n","        Person_sitting         13         27       0.78      0.852      0.859      0.601\n","                  Tram         43         62      0.873      0.935       0.96      0.785\n","                 Truck        153        161      0.951      0.958      0.977      0.857\n","                   Van        339        464      0.924      0.937      0.968      0.804\n","Speed: 0.2ms preprocess, 6.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val14\u001b[0m\n"]}]},{"cell_type":"code","source":["df = pd.DataFrame(d)\n","df_sort = df.sort_values(by='map50-95', ascending=False, ignore_index=True)\n","df_sort"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"c8t2jvjCKieH","executionInfo":{"status":"ok","timestamp":1722583706355,"user_tz":-180,"elapsed":16,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"}},"outputId":"8f8dae13-df65-4a9c-cfc1-bdd4bb36097c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      model  map50-95     map50     map75\n","0           best_yolov8x.pt  0.730817  0.933171  0.841180\n","1           last_yolov8x.pt  0.723591  0.925516  0.833438\n","2   best_yolov8x-worldv2.pt  0.719709  0.943491  0.831006\n","3           last_yolov8l.pt  0.719543  0.929570  0.827394\n","4           best_yolov8l.pt  0.714471  0.927955  0.836508\n","5   last_yolov8x-worldv2.pt  0.696421  0.926940  0.804143\n","6   best_yolov8l-worldv2.pt  0.696051  0.924406  0.800809\n","7   best_yolov8m-worldv2.pt  0.686336  0.920054  0.803312\n","8           best_yolov8m.pt  0.684232  0.917270  0.790427\n","9           last_yolov8m.pt  0.680355  0.922000  0.766252\n","10  last_yolov8l-worldv2.pt  0.672955  0.906211  0.770556\n","11  last_yolov8m-worldv2.pt  0.658262  0.901162  0.762887\n","12          best_yolov8s.pt  0.602118  0.865607  0.677463\n","13          last_yolov8s.pt  0.591423  0.865882  0.645484"],"text/html":["\n","  <div id=\"df-d537689e-dec9-459d-bcc4-756fe7f88e1f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>map50-95</th>\n","      <th>map50</th>\n","      <th>map75</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>best_yolov8x.pt</td>\n","      <td>0.730817</td>\n","      <td>0.933171</td>\n","      <td>0.841180</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>last_yolov8x.pt</td>\n","      <td>0.723591</td>\n","      <td>0.925516</td>\n","      <td>0.833438</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>best_yolov8x-worldv2.pt</td>\n","      <td>0.719709</td>\n","      <td>0.943491</td>\n","      <td>0.831006</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>last_yolov8l.pt</td>\n","      <td>0.719543</td>\n","      <td>0.929570</td>\n","      <td>0.827394</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>best_yolov8l.pt</td>\n","      <td>0.714471</td>\n","      <td>0.927955</td>\n","      <td>0.836508</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>last_yolov8x-worldv2.pt</td>\n","      <td>0.696421</td>\n","      <td>0.926940</td>\n","      <td>0.804143</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>best_yolov8l-worldv2.pt</td>\n","      <td>0.696051</td>\n","      <td>0.924406</td>\n","      <td>0.800809</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>best_yolov8m-worldv2.pt</td>\n","      <td>0.686336</td>\n","      <td>0.920054</td>\n","      <td>0.803312</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>best_yolov8m.pt</td>\n","      <td>0.684232</td>\n","      <td>0.917270</td>\n","      <td>0.790427</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>last_yolov8m.pt</td>\n","      <td>0.680355</td>\n","      <td>0.922000</td>\n","      <td>0.766252</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>last_yolov8l-worldv2.pt</td>\n","      <td>0.672955</td>\n","      <td>0.906211</td>\n","      <td>0.770556</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>last_yolov8m-worldv2.pt</td>\n","      <td>0.658262</td>\n","      <td>0.901162</td>\n","      <td>0.762887</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>best_yolov8s.pt</td>\n","      <td>0.602118</td>\n","      <td>0.865607</td>\n","      <td>0.677463</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>last_yolov8s.pt</td>\n","      <td>0.591423</td>\n","      <td>0.865882</td>\n","      <td>0.645484</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d537689e-dec9-459d-bcc4-756fe7f88e1f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d537689e-dec9-459d-bcc4-756fe7f88e1f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d537689e-dec9-459d-bcc4-756fe7f88e1f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b72c4274-383e-46d5-a493-8fb64cba4b17\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b72c4274-383e-46d5-a493-8fb64cba4b17')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b72c4274-383e-46d5-a493-8fb64cba4b17 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_sort","summary":"{\n  \"name\": \"df_sort\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"last_yolov8m.pt\",\n          \"last_yolov8m-worldv2.pt\",\n          \"best_yolov8x.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map50-95\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04261106547827561,\n        \"min\": 0.5914227457270053,\n        \"max\": 0.7308165034304994,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.6803551039015948,\n          0.6582617837547791,\n          0.7308165034304994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map50\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023311217089462218,\n        \"min\": 0.8656068733994814,\n        \"max\": 0.9434906654091163,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.9220004654076679,\n          0.90116221125959,\n          0.9331712295996237\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map75\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05891877077065771,\n        \"min\": 0.645483893953708,\n        \"max\": 0.8411798881140897,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.7662520218026643,\n          0.7628865665123414,\n          0.8411798881140897\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["best_models = ['best_yolov8x.pt', 'best_yolov8x-worldv2.pt', 'last_yolov8l.pt', 'best_yolov8l-worldv2.pt',\n","               'best_yolov8m-worldv2.pt', 'best_yolov8m.pt', 'best_yolov8s.pt']\n","df_sort_best = df_sort.set_index('model').loc[best_models]\n","df_sort_best.to_csv('finetuned_models.csv')\n","files.download('finetuned_models.csv')\n","df_sort_best"],"metadata":{"id":"bIzXbGbMUD0d","colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"status":"ok","timestamp":1722583706355,"user_tz":-180,"elapsed":11,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"}},"outputId":"95d28524-3564-40e6-890f-09ee0e340bcc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_700ac7b6-d22d-4b4d-9f6b-278dcbc6f5b5\", \"finetuned_models.csv\", 561)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["                         map50-95     map50     map75\n","model                                                \n","best_yolov8x.pt          0.730817  0.933171  0.841180\n","best_yolov8x-worldv2.pt  0.719709  0.943491  0.831006\n","last_yolov8l.pt          0.719543  0.929570  0.827394\n","best_yolov8l-worldv2.pt  0.696051  0.924406  0.800809\n","best_yolov8m-worldv2.pt  0.686336  0.920054  0.803312\n","best_yolov8m.pt          0.684232  0.917270  0.790427\n","best_yolov8s.pt          0.602118  0.865607  0.677463"],"text/html":["\n","  <div id=\"df-40f363d7-81d6-4952-a4a2-da0223728043\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>map50-95</th>\n","      <th>map50</th>\n","      <th>map75</th>\n","    </tr>\n","    <tr>\n","      <th>model</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>best_yolov8x.pt</th>\n","      <td>0.730817</td>\n","      <td>0.933171</td>\n","      <td>0.841180</td>\n","    </tr>\n","    <tr>\n","      <th>best_yolov8x-worldv2.pt</th>\n","      <td>0.719709</td>\n","      <td>0.943491</td>\n","      <td>0.831006</td>\n","    </tr>\n","    <tr>\n","      <th>last_yolov8l.pt</th>\n","      <td>0.719543</td>\n","      <td>0.929570</td>\n","      <td>0.827394</td>\n","    </tr>\n","    <tr>\n","      <th>best_yolov8l-worldv2.pt</th>\n","      <td>0.696051</td>\n","      <td>0.924406</td>\n","      <td>0.800809</td>\n","    </tr>\n","    <tr>\n","      <th>best_yolov8m-worldv2.pt</th>\n","      <td>0.686336</td>\n","      <td>0.920054</td>\n","      <td>0.803312</td>\n","    </tr>\n","    <tr>\n","      <th>best_yolov8m.pt</th>\n","      <td>0.684232</td>\n","      <td>0.917270</td>\n","      <td>0.790427</td>\n","    </tr>\n","    <tr>\n","      <th>best_yolov8s.pt</th>\n","      <td>0.602118</td>\n","      <td>0.865607</td>\n","      <td>0.677463</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40f363d7-81d6-4952-a4a2-da0223728043')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-40f363d7-81d6-4952-a4a2-da0223728043 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-40f363d7-81d6-4952-a4a2-da0223728043');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-677dc762-69b4-42b6-9906-55ddff31f324\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-677dc762-69b4-42b6-9906-55ddff31f324')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-677dc762-69b4-42b6-9906-55ddff31f324 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_sort_best","summary":"{\n  \"name\": \"df_sort_best\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"best_yolov8x.pt\",\n          \"best_yolov8x-worldv2.pt\",\n          \"best_yolov8m.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map50-95\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.043237555730902856,\n        \"min\": 0.6021177917648262,\n        \"max\": 0.7308165034304994,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7308165034304994,\n          0.7197088740959338,\n          0.6842322465337507\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map50\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025154383302320095,\n        \"min\": 0.8656068733994814,\n        \"max\": 0.9434906654091163,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9331712295996237,\n          0.9434906654091163,\n          0.9172703469655339\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map75\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05539392239933599,\n        \"min\": 0.6774625730189167,\n        \"max\": 0.8411798881140897,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.8411798881140897,\n          0.8310055686959074,\n          0.7904270029495222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["params = {'model':[], 'conf_opt':[], 'iou_opt':[]}\n","for model_path in best_models:\n","  model = YOLO('/content/weights/'+model_path)\n","  params['model'].append(model_path)\n","  metrics = model.val(data='./kitti/kitti_val.yaml')\n","  f1s = metrics.box.curves_results[1][1].mean(axis=0)\n","  confs = metrics.box.curves_results[1][0]\n","  conf_opt = confs[f1s.argmax()]\n","  ious = np.arange(0.5,1,0.05)\n","  iou_opt = ious[metrics.box.all_ap.mean(axis=0).argmax()]\n","  params['conf_opt'].append(conf_opt)\n","  params['iou_opt'].append(iou_opt)"],"metadata":{"id":"HwBQoGpGVbQh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722584075972,"user_tz":-180,"elapsed":369626,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"}},"outputId":"c917e102-7091-4858-c6c0-979f377c2cd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 268 layers, 68,131,272 parameters, 0 gradients, 257.4 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:16<00:00,  4.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.926       0.88      0.933      0.731\n","                   Car       1005       4274      0.944      0.929      0.974      0.825\n","               Cyclist        174        256      0.946      0.848      0.921      0.654\n","                  Misc        120        146      0.932      0.904      0.945       0.75\n","            Pedestrian        250        686      0.934      0.707      0.841      0.524\n","        Person_sitting         13         27      0.868      0.815      0.881      0.663\n","                  Tram         43         62      0.902      0.935      0.964      0.756\n","                 Truck        153        161       0.95      0.963      0.969      0.869\n","                   Van        339        464      0.931      0.936      0.969      0.807\n","Speed: 0.1ms preprocess, 8.6ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val15\u001b[0m\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","YOLOv8x-worldv2 summary (fused): 295 layers, 72,856,217 parameters, 0 gradients, 275.6 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:17<00:00,  4.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.925      0.892      0.943       0.72\n","                   Car       1005       4274      0.936      0.936      0.974      0.818\n","               Cyclist        174        256      0.914      0.844      0.914      0.629\n","                  Misc        120        146      0.985      0.911      0.954      0.726\n","            Pedestrian        250        686      0.923      0.733      0.844      0.524\n","        Person_sitting         13         27      0.846      0.889      0.936      0.691\n","                  Tram         43         62      0.951      0.932       0.98      0.734\n","                 Truck        153        161      0.934      0.944      0.972       0.84\n","                   Van        339        464       0.91      0.944      0.973      0.796\n","Speed: 0.1ms preprocess, 8.5ms inference, 0.0ms loss, 3.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val16\u001b[0m\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 268 layers, 43,612,776 parameters, 0 gradients, 164.8 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:13<00:00,  5.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.908      0.877       0.93       0.72\n","                   Car       1005       4274      0.938      0.933       0.97      0.814\n","               Cyclist        174        256      0.933       0.82      0.905      0.637\n","                  Misc        120        146      0.933       0.87      0.951      0.735\n","            Pedestrian        250        686      0.936      0.714      0.846      0.522\n","        Person_sitting         13         27       0.78      0.852      0.859      0.601\n","                  Tram         43         62      0.873      0.935       0.96      0.785\n","                 Truck        153        161      0.951      0.958      0.977      0.857\n","                   Van        339        464      0.924      0.937      0.968      0.804\n","Speed: 0.3ms preprocess, 6.5ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val17\u001b[0m\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","YOLOv8l-worldv2 summary (fused): 295 layers, 46,807,922 parameters, 0 gradients, 177.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [01:34<00:00,  1.34s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.914      0.853      0.924      0.696\n","                   Car       1005       4274      0.946      0.912      0.968      0.802\n","               Cyclist        174        256      0.936      0.816      0.896      0.611\n","                  Misc        120        146      0.948      0.869      0.938      0.711\n","            Pedestrian        250        686      0.944      0.665      0.841      0.512\n","        Person_sitting         13         27      0.742      0.815       0.84       0.58\n","                  Tram         43         62      0.944      0.919      0.971      0.715\n","                 Truck        153        161      0.949      0.957      0.986      0.856\n","                   Van        339        464      0.904      0.873      0.954      0.781\n","Speed: 0.2ms preprocess, 5.7ms inference, 0.0ms loss, 3.2ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val18\u001b[0m\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","YOLOv8m-worldv2 summary (fused): 245 layers, 28,358,830 parameters, 0 gradients, 87.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:12<00:00,  5.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.906      0.855       0.92      0.686\n","                   Car       1005       4274      0.929      0.916      0.962       0.79\n","               Cyclist        174        256      0.927      0.793      0.896      0.602\n","                  Misc        120        146      0.919      0.859      0.924      0.668\n","            Pedestrian        250        686      0.915      0.701      0.838      0.496\n","        Person_sitting         13         27      0.782      0.815       0.83      0.601\n","                  Tram         43         62      0.927      0.952      0.983      0.733\n","                 Truck        153        161      0.943      0.925      0.976      0.834\n","                   Van        339        464      0.906      0.877      0.952      0.767\n","Speed: 0.2ms preprocess, 4.6ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val19\u001b[0m\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 218 layers, 25,844,392 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [01:30<00:00,  1.28s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.898       0.86      0.917      0.684\n","                   Car       1005       4274      0.926       0.92      0.964      0.792\n","               Cyclist        174        256      0.886      0.832      0.898      0.612\n","                  Misc        120        146      0.911      0.842      0.921      0.689\n","            Pedestrian        250        686      0.914      0.696      0.826      0.502\n","        Person_sitting         13         27      0.799      0.815      0.852      0.556\n","                  Tram         43         62      0.892      0.931      0.949      0.707\n","                 Truck        153        161      0.943       0.95      0.973      0.849\n","                   Van        339        464      0.912      0.896      0.956      0.766\n","Speed: 0.1ms preprocess, 2.8ms inference, 0.0ms loss, 3.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val20\u001b[0m\n","Ultralytics YOLOv8.2.71 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 168 layers, 11,128,680 parameters, 0 gradients, 28.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/test.cache... 1122 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1122/1122 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:10<00:00,  7.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       1122       6076      0.882      0.786      0.866      0.602\n","                   Car       1005       4274      0.888      0.905      0.947      0.739\n","               Cyclist        174        256      0.899      0.719      0.822      0.516\n","                  Misc        120        146      0.848      0.712      0.828       0.58\n","            Pedestrian        250        686       0.84      0.641      0.757      0.431\n","        Person_sitting         13         27      0.794      0.741      0.759      0.406\n","                  Tram         43         62      0.963      0.835      0.947      0.659\n","                 Truck        153        161      0.932      0.907      0.949      0.787\n","                   Van        339        464      0.895      0.831      0.915      0.699\n","Speed: 0.1ms preprocess, 1.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val21\u001b[0m\n"]}]},{"cell_type":"code","source":["opt_params = pd.DataFrame(params)\n","opt_params.to_csv('opt_params.csv')\n","files.download('opt_params.csv')\n","opt_params"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"W5HkrqDgWRKd","executionInfo":{"status":"ok","timestamp":1722584075973,"user_tz":-180,"elapsed":12,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"}},"outputId":"fad30ef1-981f-4689-a259-305f9d011806"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_311bd296-0e3a-4ac6-85da-22aacee81f13\", \"opt_params.csv\", 335)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["                     model  conf_opt  iou_opt\n","0          best_yolov8x.pt  0.512513      0.5\n","1  best_yolov8x-worldv2.pt  0.495495      0.5\n","2          last_yolov8l.pt  0.412412      0.5\n","3  best_yolov8l-worldv2.pt  0.533534      0.5\n","4  best_yolov8m-worldv2.pt  0.493493      0.5\n","5          best_yolov8m.pt  0.500501      0.5\n","6          best_yolov8s.pt  0.413413      0.5"],"text/html":["\n","  <div id=\"df-6e26ab88-d2c1-4835-9946-4f63c9e0e74a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>conf_opt</th>\n","      <th>iou_opt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>best_yolov8x.pt</td>\n","      <td>0.512513</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>best_yolov8x-worldv2.pt</td>\n","      <td>0.495495</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>last_yolov8l.pt</td>\n","      <td>0.412412</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>best_yolov8l-worldv2.pt</td>\n","      <td>0.533534</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>best_yolov8m-worldv2.pt</td>\n","      <td>0.493493</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>best_yolov8m.pt</td>\n","      <td>0.500501</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>best_yolov8s.pt</td>\n","      <td>0.413413</td>\n","      <td>0.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e26ab88-d2c1-4835-9946-4f63c9e0e74a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6e26ab88-d2c1-4835-9946-4f63c9e0e74a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6e26ab88-d2c1-4835-9946-4f63c9e0e74a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8b16fc4f-6bb1-4d1b-8aa1-cc5187789309\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b16fc4f-6bb1-4d1b-8aa1-cc5187789309')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8b16fc4f-6bb1-4d1b-8aa1-cc5187789309 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"opt_params","summary":"{\n  \"name\": \"opt_params\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"best_yolov8x.pt\",\n          \"best_yolov8x-worldv2.pt\",\n          \"best_yolov8m.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conf_opt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04790085020449991,\n        \"min\": 0.4124124124124124,\n        \"max\": 0.5335335335335335,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.5125125125125125,\n          0.4954954954954955,\n          0.5005005005005005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"iou_opt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5,\n        \"max\": 0.5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"ZT4C2eEUHZ67"},"source":["# Eval pretrained models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jcAIbQy0GTns"},"outputs":[],"source":["zip_ref = zipfile.ZipFile(\"./kitti-dataset.zip\", 'r')\n","zip_ref.extractall(\"./kitti-eval-pretrained\")\n","zip_ref.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1721809158072,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"},"user_tz":-180},"id":"Ncn4IEsVS_Ng","outputId":"4d630f9c-3d46-48dd-e273-37134694008b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting kitti-eval-pretrained/kitti.yaml\n"]}],"source":["%%writefile kitti-eval-pretrained/kitti.yaml\n","# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n","path: ../kitti-eval-pretrained  # dataset root dir\n","train: images/test\n","val: images/test  # val images (relative to 'path') 4 images\n","\n","# Classes (8 kitti classes)\n","names:\n","  0: person\n","  1: bicycle\n","  2: car\n","  3: motorcycle\n","  4: airplane\n","  5: bus\n","  6: train\n","  7: truck"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2DudDjAGgLb"},"outputs":[],"source":["coco = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck']\n","kitti = ['car', 'bicycle', 'misc', 'person', 'person', 'train', 'truck', 'bus'] # ['car', 'bicycle', 'misc', 'person', 'person_sitting', 'tram', 'truck', 'van']\n","\n","def kitti_to_coco(label_path):\n","  with open(label_path, 'r') as file:\n","    lines = file.readlines()\n","  with open(label_path, 'w') as file:\n","    new_lines = [str(coco.index(kitti[int(line[0])]))+line[1:] for line in lines if line[0]!='2']\n","    for nw_line in new_lines:\n","      file.write(nw_line)\n","\n","tr_lb = os.listdir('./kitti-eval-pretrained/labels/train')\n","ts_lb = os.listdir('./kitti-eval-pretrained/labels/test')\n","vl_lb = os.listdir('./kitti-eval-pretrained/labels/val')\n","d = {'./kitti-eval-pretrained/labels/train':tr_lb, './kitti-eval-pretrained/labels/test':ts_lb,\n","     './kitti-eval-pretrained/labels/val':vl_lb}\n","for path in d:\n","  for lb in d[path]:\n","    kitti_to_coco(f'{path}/{lb}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YaEAJqCpHdeU"},"outputs":[],"source":["model_list = ['yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt', 'yolov9s.pt', 'yolov9m.pt',\n","              'yolov9c.pt', 'yolov9e.pt', 'yolov10s.pt', 'yolov10m.pt', 'yolov10l.pt', 'yolov10x.pt',\n","              'rtdetr-l.pt', 'yolov8s-worldv2.pt', 'yolov8m-worldv2.pt', 'yolov8l-worldv2.pt', 'yolov8x-worldv2.pt']\n","\n","d = {'model':[], 'map50-95':[], 'map50':[], 'map75':[], 'speed(ms) per image':[]}\n","for model_path in model_list:\n","  print('/////////////////////////')\n","  print(f'model = {model_path}')\n","  d['model'].append(model_path)\n","  model = YOLO(model_path)  if model_path!='rtdetr-l.pt' else RTDETR(model_path)  # load a model\n","  # Validate the model\n","  metrics = model.val(data='./kitti-eval-pretrained/kitti.yaml', batch=1)\n","  d['map50-95'].append(metrics.box.map)\n","  d['map50'].append(metrics.box.map50)\n","  d['map75'].append(metrics.box.map75)\n","  d['speed(ms) per image'].append(metrics.speed['inference'] + metrics.speed['postprocess'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWwZdy4I-MgE","executionInfo":{"status":"ok","timestamp":1721810423706,"user_tz":-180,"elapsed":89678,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"}},"outputId":"52266db4-82c0-4021-dd51-d49e15186807"},"outputs":[{"output_type":"stream","name":"stdout","text":["YOLOv8s summary: 225 layers, 11,166,560 parameters, 0 gradients, 28.8 GFLOPs\n","YOLOv8m summary: 295 layers, 25,902,640 parameters, 0 gradients, 79.3 GFLOPs\n","YOLOv8l summary: 365 layers, 43,691,520 parameters, 0 gradients, 165.7 GFLOPs\n","YOLOv8x summary: 365 layers, 68,229,648 parameters, 0 gradients, 258.5 GFLOPs\n","YOLOv9s summary: 917 layers, 7,318,368 parameters, 0 gradients, 27.6 GFLOPs\n","YOLOv9m summary: 603 layers, 20,216,160 parameters, 0 gradients, 77.9 GFLOPs\n","YOLOv9c summary: 618 layers, 25,590,912 parameters, 0 gradients, 104.0 GFLOPs\n","YOLOv9e summary: 1,225 layers, 58,206,592 parameters, 0 gradients, 193.0 GFLOPs\n","YOLOv10s summary: 402 layers, 8,128,272 parameters, 0 gradients, 25.1 GFLOPs\n","YOLOv10m summary: 498 layers, 16,576,768 parameters, 0 gradients, 64.5 GFLOPs\n","YOLOv10l summary: 628 layers, 25,888,688 parameters, 0 gradients, 127.9 GFLOPs\n","YOLOv10x summary: 688 layers, 31,808,960 parameters, 0 gradients, 171.8 GFLOPs\n","rt-detr-l summary: 673 layers, 32,970,476 parameters, 0 gradients, 108.3 GFLOPs\n","YOLOv8s-worldv2 summary: 256 layers, 12,759,880 parameters, 0 gradients, 51.0 GFLOPs\n","YOLOv8m-worldv2 summary: 326 layers, 28,376,158 parameters, 0 gradients, 110.5 GFLOPs\n","YOLOv8l-worldv2 summary: 396 layers, 46,832,050 parameters, 0 gradients, 204.5 GFLOPs\n","YOLOv8x-worldv2 summary: 396 layers, 72,886,377 parameters, 0 gradients, 309.3 GFLOPs\n","max params  = 72886377 for yolov8x-worldv2.pt\n"]}],"source":["import sys\n","\n","max_size = 0\n","for model_path in model_list:\n","  model = YOLO(model_path)\n","  size = model.info()[1]\n","  if max_size < size:\n","    max_size = size\n","    model_max = model_path\n","\n","print(f'max params  = {max_size} for {model_max}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"Flh7WhsFH24s","executionInfo":{"status":"ok","timestamp":1721811217575,"user_tz":-180,"elapsed":304,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"}},"outputId":"2179c6ee-a7b3-4cb7-84b5-5d2771f604ea"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 model  map50-95     map50     map75  speed(ms) per image\n","15  yolov8l-worldv2.pt  0.214342  0.383757  0.205743            18.762981\n","16  yolov8x-worldv2.pt  0.213372  0.380152  0.211249            18.495149\n","11         yolov10x.pt  0.211079  0.370779  0.205860            20.251225\n","7           yolov9e.pt  0.208767  0.369673  0.204226            31.252517\n","14  yolov8m-worldv2.pt  0.206188  0.361610  0.205166            15.764943\n","5           yolov9m.pt  0.199780  0.359117  0.193664            17.096423\n","10         yolov10l.pt  0.199202  0.353411  0.196966            18.947026\n","3           yolov8x.pt  0.196819  0.351723  0.192261            12.737864\n","2           yolov8l.pt  0.196650  0.352306  0.193127            12.700795\n","6           yolov9c.pt  0.194620  0.348789  0.193810            18.620049\n","9          yolov10m.pt  0.194353  0.347130  0.195541            14.937812\n","1           yolov8m.pt  0.186255  0.337447  0.185233            11.510745\n","13  yolov8s-worldv2.pt  0.179350  0.317763  0.182156            13.902298\n","4           yolov9s.pt  0.174778  0.319274  0.167939            21.562806\n","0           yolov8s.pt  0.169692  0.309502  0.161107            10.113911"],"text/html":["\n","  <div id=\"df-ccab0371-6152-420a-a8fd-8c64f27e31ae\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>map50-95</th>\n","      <th>map50</th>\n","      <th>map75</th>\n","      <th>speed(ms) per image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>15</th>\n","      <td>yolov8l-worldv2.pt</td>\n","      <td>0.214342</td>\n","      <td>0.383757</td>\n","      <td>0.205743</td>\n","      <td>18.762981</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>yolov8x-worldv2.pt</td>\n","      <td>0.213372</td>\n","      <td>0.380152</td>\n","      <td>0.211249</td>\n","      <td>18.495149</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>yolov10x.pt</td>\n","      <td>0.211079</td>\n","      <td>0.370779</td>\n","      <td>0.205860</td>\n","      <td>20.251225</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>yolov9e.pt</td>\n","      <td>0.208767</td>\n","      <td>0.369673</td>\n","      <td>0.204226</td>\n","      <td>31.252517</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>yolov8m-worldv2.pt</td>\n","      <td>0.206188</td>\n","      <td>0.361610</td>\n","      <td>0.205166</td>\n","      <td>15.764943</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>yolov9m.pt</td>\n","      <td>0.199780</td>\n","      <td>0.359117</td>\n","      <td>0.193664</td>\n","      <td>17.096423</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>yolov10l.pt</td>\n","      <td>0.199202</td>\n","      <td>0.353411</td>\n","      <td>0.196966</td>\n","      <td>18.947026</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>yolov8x.pt</td>\n","      <td>0.196819</td>\n","      <td>0.351723</td>\n","      <td>0.192261</td>\n","      <td>12.737864</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yolov8l.pt</td>\n","      <td>0.196650</td>\n","      <td>0.352306</td>\n","      <td>0.193127</td>\n","      <td>12.700795</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>yolov9c.pt</td>\n","      <td>0.194620</td>\n","      <td>0.348789</td>\n","      <td>0.193810</td>\n","      <td>18.620049</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>yolov10m.pt</td>\n","      <td>0.194353</td>\n","      <td>0.347130</td>\n","      <td>0.195541</td>\n","      <td>14.937812</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>yolov8m.pt</td>\n","      <td>0.186255</td>\n","      <td>0.337447</td>\n","      <td>0.185233</td>\n","      <td>11.510745</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>yolov8s-worldv2.pt</td>\n","      <td>0.179350</td>\n","      <td>0.317763</td>\n","      <td>0.182156</td>\n","      <td>13.902298</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>yolov9s.pt</td>\n","      <td>0.174778</td>\n","      <td>0.319274</td>\n","      <td>0.167939</td>\n","      <td>21.562806</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>yolov8s.pt</td>\n","      <td>0.169692</td>\n","      <td>0.309502</td>\n","      <td>0.161107</td>\n","      <td>10.113911</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccab0371-6152-420a-a8fd-8c64f27e31ae')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ccab0371-6152-420a-a8fd-8c64f27e31ae button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ccab0371-6152-420a-a8fd-8c64f27e31ae');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-920332da-b5c8-4d0a-9237-69f5ad6bd41d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-920332da-b5c8-4d0a-9237-69f5ad6bd41d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-920332da-b5c8-4d0a-9237-69f5ad6bd41d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_filt_sort","summary":"{\n  \"name\": \"df_filt_sort\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"yolov9c.pt\",\n          \"yolov8m.pt\",\n          \"yolov8l-worldv2.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map50-95\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01382416374329932,\n        \"min\": 0.1696916302033835,\n        \"max\": 0.214342090283329,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.19461952383152925,\n          0.18625537583364968,\n          0.214342090283329\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map50\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022177287537415442,\n        \"min\": 0.3095021398630489,\n        \"max\": 0.38375683665972543,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.34878905323361614,\n          0.33744729021270753,\n          0.38375683665972543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map75\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014096013591449918,\n        \"min\": 0.16110685496816787,\n        \"max\": 0.2112490763238286,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.19381018013801296,\n          0.1852328104887543,\n          0.20574262627711848\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speed(ms) per image\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.1801967968718765,\n        \"min\": 10.113910770246264,\n        \"max\": 31.252516569725756,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          18.62004882724102,\n          11.510744664333297,\n          18.76298076541241\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":26}],"source":["df = pd.DataFrame(d)\n","mask = (df['speed(ms) per image'] < 40.0)\n","df_filt = df[mask]\n","df_filt_sort = df_filt.sort_values(by='map50-95', ascending=False)\n","# df_filt_sort.to_csv('models_for_training.csv')\n","df_filt_sort"]},{"cell_type":"code","source":["fin_models = ['yolov8l-worldv2.pt', 'yolov8x-worldv2.pt', 'yolov8m-worldv2.pt', 'yolov8x.pt',\n","              'yolov8l.pt', 'yolov8m.pt', 'yolov8s.pt']"],"metadata":{"id":"WT15Az5F6qEX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_final = df_filt_sort.set_index('model').loc[fin_models]\n","df_final.to_csv('models_training.csv')\n","df_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"7VJ22n9d7_74","executionInfo":{"status":"ok","timestamp":1721811350630,"user_tz":-180,"elapsed":310,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"}},"outputId":"2feaf890-575d-4842-c041-da393a7e2fe7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    map50-95     map50     map75  speed(ms) per image\n","model                                                                \n","yolov8l-worldv2.pt  0.214342  0.383757  0.205743            18.762981\n","yolov8x-worldv2.pt  0.213372  0.380152  0.211249            18.495149\n","yolov8m-worldv2.pt  0.206188  0.361610  0.205166            15.764943\n","yolov8x.pt          0.196819  0.351723  0.192261            12.737864\n","yolov8l.pt          0.196650  0.352306  0.193127            12.700795\n","yolov8m.pt          0.186255  0.337447  0.185233            11.510745\n","yolov8s.pt          0.169692  0.309502  0.161107            10.113911"],"text/html":["\n","  <div id=\"df-f1103003-2acf-4178-9ce6-9f3aa46dc00d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>map50-95</th>\n","      <th>map50</th>\n","      <th>map75</th>\n","      <th>speed(ms) per image</th>\n","    </tr>\n","    <tr>\n","      <th>model</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>yolov8l-worldv2.pt</th>\n","      <td>0.214342</td>\n","      <td>0.383757</td>\n","      <td>0.205743</td>\n","      <td>18.762981</td>\n","    </tr>\n","    <tr>\n","      <th>yolov8x-worldv2.pt</th>\n","      <td>0.213372</td>\n","      <td>0.380152</td>\n","      <td>0.211249</td>\n","      <td>18.495149</td>\n","    </tr>\n","    <tr>\n","      <th>yolov8m-worldv2.pt</th>\n","      <td>0.206188</td>\n","      <td>0.361610</td>\n","      <td>0.205166</td>\n","      <td>15.764943</td>\n","    </tr>\n","    <tr>\n","      <th>yolov8x.pt</th>\n","      <td>0.196819</td>\n","      <td>0.351723</td>\n","      <td>0.192261</td>\n","      <td>12.737864</td>\n","    </tr>\n","    <tr>\n","      <th>yolov8l.pt</th>\n","      <td>0.196650</td>\n","      <td>0.352306</td>\n","      <td>0.193127</td>\n","      <td>12.700795</td>\n","    </tr>\n","    <tr>\n","      <th>yolov8m.pt</th>\n","      <td>0.186255</td>\n","      <td>0.337447</td>\n","      <td>0.185233</td>\n","      <td>11.510745</td>\n","    </tr>\n","    <tr>\n","      <th>yolov8s.pt</th>\n","      <td>0.169692</td>\n","      <td>0.309502</td>\n","      <td>0.161107</td>\n","      <td>10.113911</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1103003-2acf-4178-9ce6-9f3aa46dc00d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f1103003-2acf-4178-9ce6-9f3aa46dc00d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f1103003-2acf-4178-9ce6-9f3aa46dc00d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3bbf3c9b-82b8-4a66-a3b4-478791a00119\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3bbf3c9b-82b8-4a66-a3b4-478791a00119')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3bbf3c9b-82b8-4a66-a3b4-478791a00119 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_final","summary":"{\n  \"name\": \"df_final\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"yolov8l-worldv2.pt\",\n          \"yolov8x-worldv2.pt\",\n          \"yolov8m.pt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map50-95\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015874010836512163,\n        \"min\": 0.1696916302033835,\n        \"max\": 0.214342090283329,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.214342090283329,\n          0.21337227639809628,\n          0.18625537583364968\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map50\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025459428830423823,\n        \"min\": 0.3095021398630489,\n        \"max\": 0.38375683665972543,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.38375683665972543,\n          0.3801521353835138,\n          0.33744729021270753\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"map75\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016932630321630022,\n        \"min\": 0.16110685496816787,\n        \"max\": 0.2112490763238286,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.20574262627711848,\n          0.2112490763238286,\n          0.1852328104887543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speed(ms) per image\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.4147843636192605,\n        \"min\": 10.113910770246264,\n        \"max\": 18.76298076541241,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          18.76298076541241,\n          18.495148515956284,\n          11.510744664333297\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"klWhrGmqjvx-"},"source":["# Train (fine-tune)"]},{"cell_type":"code","source":["fin_models = ['yolov8l-worldv2.pt', 'yolov8x-worldv2.pt', 'yolov8m-worldv2.pt', 'yolov8x.pt',\n","              'yolov8l.pt', 'yolov8m.pt', 'yolov8s.pt']"],"metadata":{"id":"Pg1KRJuP9pAj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_res(model_path):\n","  fs = os.listdir(f'/content/runs/train_{model_path[:-3]}')\n","  fs.remove('weights')\n","  os.makedirs(f'/content/train_{model_path[:-3]}', exist_ok=True)\n","  for f in fs:\n","    copy(f'/content/runs/train_{model_path[:-3]}/{f}', f'/content/train_{model_path[:-3]}')\n","  make_archive(f'train_{model_path[:-3]}', 'zip', f'/content/train_{model_path[:-3]}')\n","  os.rename(f'/content/runs/train_{model_path[:-3]}/weights/best.pt',\n","            f'/content/runs/train_{model_path[:-3]}/weights/best_{model_path[:-3]}.pt')\n","  os.rename(f'/content/runs/train_{model_path[:-3]}/weights/last.pt',\n","            f'/content/runs/train_{model_path[:-3]}/weights/last_{model_path[:-3]}.pt')\n","  files.download(f'/content/runs/train_{model_path[:-3]}/weights/best_{model_path[:-3]}.pt')\n","  time.sleep(30)\n","  files.download(f'/content/runs/train_{model_path[:-3]}/weights/last_{model_path[:-3]}.pt')\n","  time.sleep(10)\n","  files.download(f'train_{model_path[:-3]}.zip')"],"metadata":{"id":"37wH8GJ1uT61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model_path):\n","  model = YOLO(model_path)\n","  results = model.train(data=\"kitti/kitti.yaml\", epochs=40, freeze=10, project='runs', name=f'train_{model_path[:-3]}')\n","  save_res(model_path)\n","  return (model, results)"],"metadata":{"id":"LDs6Mt09_FuY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V7x4LfYkkOan"},"outputs":[],"source":["# for model_path in fin_models[1:]:\n","#   # Load a model\n","#   model = YOLO(model_path)  # load a pretrained model (recommended for training)\n","\n","#   # Train the model\n","#   results = model.train(data=\"kitti/kitti.yaml\", epochs=40, freeze=10, project='runs', name=f'train_{model_path[:-3]}')\n","#   # save_res(model_path)\n","#   # n_layers = model.info()[0]"]},{"cell_type":"code","source":["d_res = {}"],"metadata":{"id":"QbnwNDGo_fn5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d_res[fin_models[6]] = train_model(fin_models[6])"],"metadata":{"id":"EOvycfbJ_7IZ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1722448465635,"user_tz":-180,"elapsed":1776561,"user":{"displayName":"Glib Sukhomlyn","userId":"02768671175215009155"}},"outputId":"910a7150-3d8f-41c5-9035-888dd0a0fa96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:00<00:00, 267MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=kitti/kitti.yaml, epochs=40, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs, name=train_yolov8s, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/train_yolov8s\n","Overriding model.yaml nc=80 with nc=8\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n","Model summary: 225 layers, 11,138,696 parameters, 11,138,680 gradients, 28.7 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train_yolov8s', view at http://localhost:6006/\n","Freezing layer 'model.0.conv.weight'\n","Freezing layer 'model.0.bn.weight'\n","Freezing layer 'model.0.bn.bias'\n","Freezing layer 'model.1.conv.weight'\n","Freezing layer 'model.1.bn.weight'\n","Freezing layer 'model.1.bn.bias'\n","Freezing layer 'model.2.cv1.conv.weight'\n","Freezing layer 'model.2.cv1.bn.weight'\n","Freezing layer 'model.2.cv1.bn.bias'\n","Freezing layer 'model.2.cv2.conv.weight'\n","Freezing layer 'model.2.cv2.bn.weight'\n","Freezing layer 'model.2.cv2.bn.bias'\n","Freezing layer 'model.2.m.0.cv1.conv.weight'\n","Freezing layer 'model.2.m.0.cv1.bn.weight'\n","Freezing layer 'model.2.m.0.cv1.bn.bias'\n","Freezing layer 'model.2.m.0.cv2.conv.weight'\n","Freezing layer 'model.2.m.0.cv2.bn.weight'\n","Freezing layer 'model.2.m.0.cv2.bn.bias'\n","Freezing layer 'model.3.conv.weight'\n","Freezing layer 'model.3.bn.weight'\n","Freezing layer 'model.3.bn.bias'\n","Freezing layer 'model.4.cv1.conv.weight'\n","Freezing layer 'model.4.cv1.bn.weight'\n","Freezing layer 'model.4.cv1.bn.bias'\n","Freezing layer 'model.4.cv2.conv.weight'\n","Freezing layer 'model.4.cv2.bn.weight'\n","Freezing layer 'model.4.cv2.bn.bias'\n","Freezing layer 'model.4.m.0.cv1.conv.weight'\n","Freezing layer 'model.4.m.0.cv1.bn.weight'\n","Freezing layer 'model.4.m.0.cv1.bn.bias'\n","Freezing layer 'model.4.m.0.cv2.conv.weight'\n","Freezing layer 'model.4.m.0.cv2.bn.weight'\n","Freezing layer 'model.4.m.0.cv2.bn.bias'\n","Freezing layer 'model.4.m.1.cv1.conv.weight'\n","Freezing layer 'model.4.m.1.cv1.bn.weight'\n","Freezing layer 'model.4.m.1.cv1.bn.bias'\n","Freezing layer 'model.4.m.1.cv2.conv.weight'\n","Freezing layer 'model.4.m.1.cv2.bn.weight'\n","Freezing layer 'model.4.m.1.cv2.bn.bias'\n","Freezing layer 'model.5.conv.weight'\n","Freezing layer 'model.5.bn.weight'\n","Freezing layer 'model.5.bn.bias'\n","Freezing layer 'model.6.cv1.conv.weight'\n","Freezing layer 'model.6.cv1.bn.weight'\n","Freezing layer 'model.6.cv1.bn.bias'\n","Freezing layer 'model.6.cv2.conv.weight'\n","Freezing layer 'model.6.cv2.bn.weight'\n","Freezing layer 'model.6.cv2.bn.bias'\n","Freezing layer 'model.6.m.0.cv1.conv.weight'\n","Freezing layer 'model.6.m.0.cv1.bn.weight'\n","Freezing layer 'model.6.m.0.cv1.bn.bias'\n","Freezing layer 'model.6.m.0.cv2.conv.weight'\n","Freezing layer 'model.6.m.0.cv2.bn.weight'\n","Freezing layer 'model.6.m.0.cv2.bn.bias'\n","Freezing layer 'model.6.m.1.cv1.conv.weight'\n","Freezing layer 'model.6.m.1.cv1.bn.weight'\n","Freezing layer 'model.6.m.1.cv1.bn.bias'\n","Freezing layer 'model.6.m.1.cv2.conv.weight'\n","Freezing layer 'model.6.m.1.cv2.bn.weight'\n","Freezing layer 'model.6.m.1.cv2.bn.bias'\n","Freezing layer 'model.7.conv.weight'\n","Freezing layer 'model.7.bn.weight'\n","Freezing layer 'model.7.bn.bias'\n","Freezing layer 'model.8.cv1.conv.weight'\n","Freezing layer 'model.8.cv1.bn.weight'\n","Freezing layer 'model.8.cv1.bn.bias'\n","Freezing layer 'model.8.cv2.conv.weight'\n","Freezing layer 'model.8.cv2.bn.weight'\n","Freezing layer 'model.8.cv2.bn.bias'\n","Freezing layer 'model.8.m.0.cv1.conv.weight'\n","Freezing layer 'model.8.m.0.cv1.bn.weight'\n","Freezing layer 'model.8.m.0.cv1.bn.bias'\n","Freezing layer 'model.8.m.0.cv2.conv.weight'\n","Freezing layer 'model.8.m.0.cv2.bn.weight'\n","Freezing layer 'model.8.m.0.cv2.bn.bias'\n","Freezing layer 'model.9.cv1.conv.weight'\n","Freezing layer 'model.9.cv1.bn.weight'\n","Freezing layer 'model.9.cv1.bn.bias'\n","Freezing layer 'model.9.cv2.conv.weight'\n","Freezing layer 'model.9.cv2.bn.weight'\n","Freezing layer 'model.9.cv2.bn.bias'\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kitti/labels/train.cache... 5984 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5984/5984 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kitti/labels/val.cache... 375 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/train_yolov8s/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/train_yolov8s\u001b[0m\n","Starting training for 40 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/40      4.35G      1.297      1.567      1.091        145        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:47<00:00,  7.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  6.04it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.552      0.488      0.533      0.315\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/40      4.18G      1.189      0.913      1.043        177        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:41<00:00,  8.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.21it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.759       0.48        0.6       0.36\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/40      4.18G      1.166      0.856      1.036        178        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.67it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.744      0.583      0.661      0.399\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/40      4.17G      1.131     0.8101      1.023        164        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.698      0.606      0.681      0.419\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/40      4.17G      1.103     0.7741      1.011        191        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.626      0.663      0.697      0.435\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/40      4.17G      1.078     0.7451      0.999        109        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  6.97it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.813      0.633      0.733      0.462\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/40      4.17G       1.07     0.7268     0.9969        212        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105       0.75      0.682      0.739      0.477\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/40      4.17G      1.041     0.7018     0.9859        186        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.849      0.664      0.766      0.487\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/40      4.17G      1.031      0.688     0.9826        138        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.821      0.662      0.761      0.492\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/40      4.17G      1.018     0.6715     0.9756        217        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.13it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.753      0.714      0.764      0.491\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/40      4.17G      1.007     0.6667     0.9736        202        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.846      0.672      0.783      0.511\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/40      4.17G     0.9966     0.6519     0.9678        205        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.13it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.819      0.684      0.793      0.519\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/40      4.17G     0.9802     0.6372     0.9648        170        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.55it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.839      0.699      0.803      0.528\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/40      4.17G     0.9731     0.6348     0.9607        160        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.819      0.711      0.794      0.533\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/40      4.17G     0.9657     0.6223     0.9556        152        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.822      0.705      0.817      0.542\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/40      4.17G     0.9558     0.6135     0.9516        172        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  6.93it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.792      0.748      0.827      0.558\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/40      4.17G     0.9522       0.61     0.9522        195        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.08it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.859      0.705       0.82      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/40      4.17G     0.9462     0.6038     0.9495        175        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105       0.84      0.716      0.815      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/40      4.17G     0.9379     0.5953     0.9453        135        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.49it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.856      0.733       0.82      0.567\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/40      4.17G     0.9315     0.5913     0.9448        179        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.26it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.845      0.755      0.821       0.56\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      21/40      4.17G     0.9205     0.5796     0.9407        133        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105       0.81       0.76      0.836      0.565\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      22/40      4.17G     0.9122     0.5757     0.9377        176        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.847      0.734       0.83      0.573\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      23/40      4.17G      0.911     0.5704     0.9346        223        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.61it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.838      0.781      0.853      0.581\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      24/40      4.17G     0.8986     0.5653     0.9327        122        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.883      0.735      0.852      0.579\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      25/40      4.17G     0.8992     0.5624     0.9331        216        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.34it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.882       0.73      0.847      0.578\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      26/40      4.17G     0.8858     0.5564     0.9294        206        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.906      0.737      0.852      0.586\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      27/40      4.17G     0.8905     0.5545     0.9282        160        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.18it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.887      0.743      0.857      0.588\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      28/40      4.17G     0.8822     0.5483     0.9261        183        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:40<00:00,  9.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.881      0.774      0.854      0.587\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      29/40      4.17G     0.8785     0.5447      0.926        159        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.90it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.884      0.755      0.851      0.596\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      30/40      4.17G     0.8718     0.5394     0.9226        194        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.16it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.877      0.753      0.845      0.594\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      31/40      4.17G     0.9413     0.5864     0.9428         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:41<00:00,  9.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.12it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.803      0.744      0.807      0.537\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      32/40      4.17G     0.9266     0.5699     0.9384         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.60it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.829      0.748      0.818      0.544\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      33/40      4.17G     0.9147     0.5598     0.9323         94        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.793      0.775       0.83      0.557\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      34/40      4.17G      0.901     0.5501     0.9281         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.823      0.745      0.827      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      35/40      4.17G     0.8985     0.5456     0.9266         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.47it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.868      0.731      0.826      0.555\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      36/40      4.17G      0.888     0.5384     0.9226         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.831      0.739       0.83      0.555\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      37/40      4.17G     0.8842      0.535     0.9207         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.28it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.865      0.733      0.826      0.558\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      38/40      4.17G     0.8801     0.5274     0.9195        109        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.871      0.729      0.835      0.558\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      39/40      4.17G     0.8673      0.521      0.917         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:38<00:00,  9.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.871      0.733      0.845      0.565\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      40/40      4.17G     0.8697     0.5202     0.9165         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:39<00:00,  9.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  7.33it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.862      0.755      0.845      0.563\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","40 epochs completed in 0.476 hours.\n","Optimizer stripped from runs/train_yolov8s/weights/last.pt, 22.5MB\n","Optimizer stripped from runs/train_yolov8s/weights/best.pt, 22.5MB\n","\n","Validating runs/train_yolov8s/weights/best.pt...\n","Ultralytics YOLOv8.2.70 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA L4, 22700MiB)\n","Model summary (fused): 168 layers, 11,128,680 parameters, 0 gradients, 28.5 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:05<00:00,  2.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        375       2105      0.884      0.755      0.851      0.596\n","                   Car        336       1478      0.896      0.878      0.938      0.728\n","               Cyclist         56         86      0.821       0.64      0.747      0.493\n","                  Misc         29         36      0.841       0.75      0.886      0.555\n","            Pedestrian         94        243      0.885      0.646      0.748      0.412\n","        Person_sitting          9         19       0.97      0.474      0.646      0.439\n","                  Tram         20         26      0.885      0.962      0.987      0.694\n","                 Truck         53         58      0.873      0.862      0.933      0.744\n","                   Van        119        159      0.898      0.831      0.922      0.701\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1mruns/train_yolov8s\u001b[0m\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_c3b14c7d-c8d8-45bd-9477-9c5406a2ba5c\", \"best_yolov8s.pt\", 22484643)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_023b26a3-d9c4-447c-83fc-1ed4561b7597\", \"last_yolov8s.pt\", 22485987)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_2ca3065b-2948-4177-bf69-f117367a82fa\", \"train_yolov8s.zip\", 5647577)"]},"metadata":{}}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["KtY6Rvf2Lb2O","qTwuxu1WRt8j","ZT4C2eEUHZ67"],"gpuType":"L4","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPM5C+xo1bEXSQx1PDXe6vU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
